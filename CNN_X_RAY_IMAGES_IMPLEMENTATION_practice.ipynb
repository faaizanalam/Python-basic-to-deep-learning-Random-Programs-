# %%
import os
import numpy as np
import cv2
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
from keras.models import Model

# %%
# Define the paths to the data folders
train_path = "xray_dataset/xray_dataset/train_data"
test_path = "xray_dataset/xray_dataset/test_data"
#val_path = "xray_dataset/xray_dataset/validation_data"

# %%
# Define the classes and the number of classes
classes = ["COVID-19", "Normal","Pneumonia-Bacterial","Pneumonia-Viral"]
num_classes = len(classes)
# Define the image size and the batch size
img_size = 128
batch_size = 8

# %%
def load_data(path):
  images = []
  labels = []
  # Loop through each subfolder in the path
  for folder in os.listdir(path):
    class_index = classes.index(folder)
    for file in os.listdir(os.path.join(path, folder)):
      image = cv2.imread(os.path.join(path, folder, file))
      image = cv2.resize(image, (img_size, img_size))
      image = image / 255.0
      images.append(image)
      labels.append(class_index)
  images = np.array(images)
  labels = np.array(labels)
  return images, labels

# %%
train_images, train_labels = load_data(train_path)
test_images, test_labels = load_data(test_path)
#val_images, val_labels = load_data(val_path)
train_images.shape

# %%
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(16, (3, 3), activation="relu", input_shape=(img_size, img_size, 3)),
  tf.keras.layers.Conv2D(16, (3, 3), activation="relu"),
  tf.keras.layers.Conv2D(8, (3, 3), activation="relu"),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(8, activation="relu"),
  tf.keras.layers.Dropout(0.2),
  # Add an output layer with num_classes units and softmax activation for multi-class classification
  tf.keras.layers.Dense(num_classes, activation="softmax")
])

# %% [markdown]
# ### model.compile is used to configure the learning process of the model. it has three parameters.
# <b>1. Optimizer</b>
# It determines how the model updates its weights during training. Optimizers minimize the loss function by adjusting weights in the network through backpropagation.<br>
# Examples:<br>
# 'adam' (Adaptive Moment Estimation): Combines momentum and adaptive learning rates, widely used for CNNs.<br>
# 'sgd' (Stochastic Gradient Descent): Updates weights based on gradients and a learning rate.
# 'rmsprop' (Root Mean Square Propagation): Popular for recurrent neural networks but also applicable in CNNs.<br>
# <b>2. Loss Function:</b><br>
# Measures the difference between the predicted output and the actual target. The model tries to minimize this value.<br>
# Examples:<br>
# For binary classification: 'binary_crossentropy'<br>
# For multi-class classification: 'categorical_crossentropy' (for one-hot encoded labels) or 'sparse_categorical_crossentropy' (for integer-encoded labels).
# For regression tasks: 'mean_squared_error'<br>
# <b>3. Metric:</b><br>
# Specifies performance metrics to monitor during training and evaluation.<br>
# Examples:<br>
# <b>'accuracy':</b> Measures how often predictions match labels.<br>
# <b>'precision':</b>, 'recall': Useful for imbalanced datasets.<br>
# <b>'mae' (Mean Absolute Error):</b> Common in regression tasks.<br>
# 

# %%
model.compile(loss="sparse_categorical_crossentropy", optimizer="sgd", metrics=["accuracy"])

# %%
history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=40)
#model.summary()

# %%
model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

# %%
history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=4)
#model.summary()

# %%
model.compile(loss="sparse_categorical_crossentropy", optimizer="rmsprop", metrics=["accuracy"])

# %%
history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=10)
#model.summary()

# %%
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np

# Get predictions
y_pred_probs = model.predict(test_images, batch_size=batch_size)  # Probabilities
y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels

# Compute confusion matrix
conf_matrix = confusion_matrix(test_labels, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)

# Optionally, print classification report
print("Classification Report:")
print(classification_report(test_labels, y_pred))


# %%



